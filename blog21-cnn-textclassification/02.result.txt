Python 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 19:29:22) [MSC v.1916 32 bit (Intel)] on win32
Type "help", "copyright", "credits" or "license()" for more information.
>>> 
 RESTART: D:/[重点] 博客开源代码/[重点] 6.Python人工智能/Python+TensorFlow人工智能/blog-21 keras-cnn-textclassifier/02.read_csv_ML.py 
Building prefix dict from the default dictionary ...
Loading model from cache C:\Users\xiuzhang\AppData\Local\Temp\jieba.cache
Loading model cost 1.586 seconds.
Prefix dict has been built succesfully.
[0, 0, 0, 0, 0]
['还 记得 小时候 ， 常常 守 在 电视机 前 ， 等候 《 西游记 》 的 播出 。 “ 你 挑 着 担 , 我 牵 着 马 。 翻山 涉水 两肩 双滑 … … " 熟悉 的 歌曲 ， 又 在 耳边 响起 时 。   这 歌词 中 的 水 ， 就 有 贵州 的 水 ， 准确 的 说 ， 是 贵州 的 黄果树 瀑布 ； 那一帘 瀑布 ， 流进 了 我们 的 童年 ， 让 我们 流连忘返 。   黄果树 瀑布 并 不是 只有 一个 瀑布 ， 而是 一个 大 景区 ， 包括 陡坡 塘 瀑布 、 天星桥 景区 、 黄果树 大 瀑布 ， 其中 黄果树 大 瀑布 是 最 有名 的 。 \n 收起 评论', '飞流直下三千尺   疑是 银河 落九天 ！', '黄果树 大 瀑布 景区 ， 位置 坐落 在 贵州省 安顺市 关岭 县 黄果树 风景区 。 这里 是 贵州省 最 著名 的 景区 。 也 是 中国 最美 的 瀑布 ， 享有 有 中华 第一 瀑布 的 美名 ， 更是 世界 吉尼斯 纪录 里 认证 的 世界 最大 的 瀑布群 ， 说 到 瀑布群 ， 它 蕴含着 大小 瀑布 十八个 。 \n 收起 评论', '国家 重点 风景 名胜区 和 首批 国家 5A 级 旅游 景区   今天 黄果树 景区 时而 艳阳高照 ， 时而 瓢泼大雨 ； 当地人 说 两个 多月 没有 这么 晴朗 的 天空 更是 没有 下雨 ； 我们 如此这般 幸运 一会 晒 脸 ? ?   一会 挨 浇 ?   ? ?   人品 爆棚 ， 但 景区 内 风景秀丽 、 环境优美 ， 值得 值得 \n 收起 评论', '黄果树 瀑布群 绝对 是 值得一看 的 。 景区 非常 大 ， 不止 黄果树 瀑布 ， 天星桥 景区 绝对 不要 错过 。 那个 天生桥 下方 的 珍珠 链 瀑布 ， 很 值得一看 。 这个 瀑布 比 黄果树 的 观景 距离 近多 了 ， 基本上 可以 触摸 得到 的 水花 水汽 ， 白链 如珠 ， 水流 很 急 ， 特别 壮观 。 当然 ， 它 实际上 也 很 危险 。 就 在 我们 游玩 过后 的 一个 星期 ， 就 有 母子 二人 在 这个 瀑布 身亡 。 实际上 黄果树 的 所有 瀑布 都 是 只 给 在 栏杆 外远观 的 ， 无视 栏杆 走近 水边 ， 这么 急 的 水流 ， 危险 可想而知 。 \n 收起 评论']
  (0, 3774)	0.18729017450706106
  (0, 3620)	0.09207733718859397
  (0, 3523)	0.1872989847090927
  (0, 3281)	0.14747480986590775
  (0, 3247)	0.04089137740247993
  (0, 3234)	0.1517704263475748
  (0, 3193)	0.09663974675158442
  (0, 3067)	0.17418645091935644
  (0, 3062)	0.1517704263475748
  (0, 3041)	0.1872989847090927
  (0, 2930)	0.17418645091935644
  (0, 2908)	0.1872989847090927
  (0, 2711)	0.1872989847090927
  (0, 2631)	0.17418645091935644
  (0, 2588)	0.29752944778183016
  (0, 2518)	0.1872989847090927
  (0, 2499)	0.17418645091935644
  (0, 2498)	0.1872989847090927
  (0, 2346)	0.1872989847090927
  (0, 2345)	0.1872989847090927
  (0, 2245)	0.1386578925578385
  (0, 2180)	0.10027330253927719
  (0, 2048)	0.04089137740247993
  (0, 2040)	0.1872989847090927
  (0, 1883)	0.16640438050256437
  (0, 1651)	0.1872989847090927
  (0, 1550)	0.1517704263475748
  (0, 1363)	0.08589870875014204
  (0, 1135)	0.17418645091935644
  (0, 1039)	0.13525058748018745
  (0, 999)	0.1872989847090927
  (0, 896)	0.1517704263475748
  (0, 761)	0.1872989847090927
  (0, 722)	0.1424669355655294
  (0, 343)	0.1872989847090927
  (0, 293)	0.09866162305381218
  (0, 78)	0.14464170113126407
  (0, 3728)	0.514357000682876
  (0, 3569)	0.4951218287278785
  (0, 3151)	0.4951218287278785
  (0, 2726)	0.4951218287278785
  (0, 3774)	0.11250283947183416
  (0, 3712)	0.15878365912722409
  (0, 3459)	0.11852957871033616
  (0, 3282)	0.26732200487909735
  (0, 3247)	0.04912586663770711
  (0, 3230)	0.19808621829512352
  (0, 3161)	0.22501626329757252
  (0, 3155)	0.13185361412477511
  (0, 3028)	0.22501626329757252
  (0, 2966)	0.20926319682840672
  (0, 2913)	0.13185361412477511
  (0, 2590)	0.27509885839168896
  (0, 2588)	0.20425391646971228
  (0, 2228)	0.20926319682840672
  (0, 2219)	0.13185361412477511
  (0, 2208)	0.17634411391116353
  (0, 2180)	0.12046580968358972
  (0, 2048)	0.04912586663770711
  (0, 1480)	0.14187075003931182
  (0, 1332)	0.1624866352098052
  (0, 1240)	0.22501626329757252
  (0, 1081)	0.20926319682840672
  (0, 920)	0.22501626329757252
  (0, 715)	0.19808621829512352
  (0, 580)	0.18941668021225422
  (0, 463)	0.19808621829512352
  (0, 354)	0.14941406890871453
  (0, 352)	0.18941668021225422
  (0, 325)	0.2537741042489736
  (0, 3774)	0.045860021232339086
  (0, 3739)	0.17060573217088465
  (0, 3714)	0.1614934915331167
  (0, 3710)	0.09767206175659159
  (0, 3560)	0.13953826904454383
  (0, 3439)	0.11566278041683704
  (0, 3247)	0.04005078089831391
  (0, 3124)	0.18344871402168958
  (0, 2692)	0.18344871402168958
  (0, 2680)	0.18344871402168958
  (0, 2634)	0.18344871402168958
  (0, 2455)	0.1390099223096385
  (0, 2208)	0.1437678345920976
  (0, 2191)	0.18344871402168958
  (0, 2180)	0.14731800412673465
  (0, 2148)	0.36689742804337916
  (0, 2101)	0.10100932349212899
  (0, 2048)	0.04005078089831391
  (0, 1883)	0.08149181817024923
  (0, 1713)	0.14865050968231178
  (0, 1670)	0.1544254885845423
  (0, 1443)	0.18344871402168958
  (0, 1370)	0.17060573217088465
  (0, 1303)	0.17060573217088465
  (0, 1196)	0.27907653808908767
  (0, 1096)	0.13580752783150682
  (0, 624)	0.21499224630100788
  (0, 517)	0.1544254885845423
  (0, 479)	0.18344871402168958
  (0, 332)	0.10896963025271979
  (0, 241)	0.13953826904454383
  (0, 84)	0.36689742804337916
  (0, 51)	0.10896963025271979

<class 'scipy.sparse.csr.csr_matrix'>
00
10
100
1000
101
单词数量: 3785
(240, 3785)
随机森林分类
              precision    recall  f1-score   support

           0       0.92      0.88      0.90        41
           1       0.85      0.90      0.88        31

    accuracy                           0.89        72
   macro avg       0.89      0.89      0.89        72
weighted avg       0.89      0.89      0.89        72

算法评价: RandomForest
28 36 33 39 31 41
Precision Good 0:0.9231
Precision Bad 1:0.8485
Avg_precision:0.8858
Recall Good 0:0.8780
Recall Bad 1:0.9032
Avg_recall:0.8906
F-measure Good 0:0.9000
F-measure Bad 1:0.8750
Avg_fmeasure:0.8875


决策树分类
              precision    recall  f1-score   support

           0       0.81      0.73      0.77        41
           1       0.69      0.77      0.73        31

    accuracy                           0.75        72
   macro avg       0.75      0.75      0.75        72
weighted avg       0.76      0.75      0.75        72

算法评价: DecisionTree
24 30 35 37 31 41
Precision Good 0:0.8108
Precision Bad 1:0.6857
Avg_precision:0.7483
Recall Good 0:0.7317
Recall Bad 1:0.7742
Avg_recall:0.7530
F-measure Good 0:0.7692
F-measure Bad 1:0.7273
Avg_fmeasure:0.7483


支持向量机分类
              precision    recall  f1-score   support

           0       0.92      0.88      0.90        41
           1       0.85      0.90      0.88        31

    accuracy                           0.89        72
   macro avg       0.89      0.89      0.89        72
weighted avg       0.89      0.89      0.89        72

算法评价: LinearSVC
28 36 33 39 31 41
Precision Good 0:0.9231
Precision Bad 1:0.8485
Avg_precision:0.8858
Recall Good 0:0.8780
Recall Bad 1:0.9032
Avg_recall:0.8906
F-measure Good 0:0.9000
F-measure Bad 1:0.8750
Avg_fmeasure:0.8875


最近邻分类
              precision    recall  f1-score   support

           0       0.89      0.83      0.86        41
           1       0.79      0.87      0.83        31

    accuracy                           0.85        72
   macro avg       0.84      0.85      0.85        72
weighted avg       0.85      0.85      0.85        72

算法评价: KNeighbors
27 34 34 38 31 41
Precision Good 0:0.8947
Precision Bad 1:0.7941
Avg_precision:0.8444
Recall Good 0:0.8293
Recall Bad 1:0.8710
Avg_recall:0.8501
F-measure Good 0:0.8608
F-measure Bad 1:0.8308
Avg_fmeasure:0.8458


朴素贝叶斯分类
              precision    recall  f1-score   support

           0       0.90      0.93      0.92        41
           1       0.90      0.87      0.89        31

    accuracy                           0.90        72
   macro avg       0.90      0.90      0.90        72
weighted avg       0.90      0.90      0.90        72

算法评价: MultinomialNB
27 38 30 42 31 41
Precision Good 0:0.9048
Precision Bad 1:0.9000
Avg_precision:0.9024
Recall Good 0:0.9268
Recall Bad 1:0.8710
Avg_recall:0.8989
F-measure Good 0:0.9157
F-measure Bad 1:0.8852
Avg_fmeasure:0.9005


逻辑回归分类
              precision    recall  f1-score   support

           0       0.92      0.88      0.90        41
           1       0.85      0.90      0.88        31

    accuracy                           0.89        72
   macro avg       0.89      0.89      0.89        72
weighted avg       0.89      0.89      0.89        72

算法评价: LogisticRegression
28 36 33 39 31 41
Precision Good 0:0.9231
Precision Bad 1:0.8485
Avg_precision:0.8858
Recall Good 0:0.8780
Recall Bad 1:0.9032
Avg_recall:0.8906
F-measure Good 0:0.9000
F-measure Bad 1:0.8750
Avg_fmeasure:0.8875


>>> 
